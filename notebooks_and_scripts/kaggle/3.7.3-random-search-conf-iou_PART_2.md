---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.17.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```python _cell_guid="004c9494-8c98-46ea-96fb-b37bd20e705f" _uuid="26bf2953-4c1f-452c-bb7b-0340b935ed94" jupyter={"outputs_hidden": false} papermill={"duration": 89.807244, "end_time": "2025-07-26T17:25:39.653284", "exception": false, "start_time": "2025-07-26T17:24:09.846040", "status": "completed"}
pip install ultralytics rfdetr
```

```python _cell_guid="97411331-38e6-4b6e-b2ca-0d7a6b4756a5" _uuid="71685076-fc0c-48b2-ab4d-60f6b429bf70" jupyter={"outputs_hidden": false} papermill={"duration": 0.031709, "end_time": "2025-07-26T17:25:39.712428", "exception": false, "start_time": "2025-07-26T17:25:39.680719", "status": "completed"}
import sys
sys.path.append("/kaggle/input/dpm3-src")
```

<!-- #region _cell_guid="e36487a8-b1e0-4e3c-b2b1-0efaa4805b91" _uuid="c0a82671-b42d-4701-8555-05b9290d8a09" jupyter={"outputs_hidden": false} papermill={"duration": 0.025883, "end_time": "2025-07-26T17:25:39.764723", "exception": false, "start_time": "2025-07-26T17:25:39.738840", "status": "completed"} -->
 ## 1. Load the mdoels, show example of the inference
<!-- #endregion -->

```python _cell_guid="8e3e7b15-66e1-4fc6-9ee9-dc31523d4a05" _uuid="785d1eaf-1f27-4978-bd9e-c642f6ab2922" jupyter={"outputs_hidden": false} papermill={"duration": 11.035124, "end_time": "2025-07-26T17:25:50.826214", "exception": false, "start_time": "2025-07-26T17:25:39.791090", "status": "completed"}
from src.odc.benchmark import (
    UltralyticsModel,
    FasterRCNNModel,
    RFDETRModel,
    SkyFusionDataset,
)
```

```python _cell_guid="398e0b1d-ce5d-4439-b197-f053d28b8c83" _uuid="2d05e1d3-702e-4482-abf6-ec1e97338624" jupyter={"outputs_hidden": false} papermill={"duration": 0.035824, "end_time": "2025-07-26T17:25:50.888853", "exception": false, "start_time": "2025-07-26T17:25:50.853029", "status": "completed"}
models_config: dict = {
    "models": [
        {
            "name": "rt-detr",
            "path": "/kaggle/input/dpm3-models/models/rtdetr-aug_best.pt",
            "type": "rtdetr",
            "use_for_eval": True,
        },
        {
            "name": "faster-rcnn",
            "path": "/kaggle/input/dpm3-models/models/fasterrcnn-best-epoch=18-val_map=0.31.ckpt",
            "type": "faster-rcnn",
            "use_for_eval": True,
        },
        {
            "name": "yolov11m-aug_20250603",
            "path": "/kaggle/input/dpm3-models/models/yolov11m-aug_20250603.pt",
            "type": "yolo",
            "use_for_eval": False,

        },
        {
            "name": "yolov11m-p2-aug_20250603",
            "path": "/kaggle/input/dpm3-models/models/yolov11m-p2-aug_20250603.pt",
            "type": "yolo",
            "use_for_eval": True,
        },
        {
            "name": "yolov8m-aug-100epochs-cos-lr_20250518",
            "path": "/kaggle/input/dpm3-models/models/yolov8m-aug-100epochs-cos-lr_20250518.pt",
            "type": "yolo",
            "use_for_eval": False,

        },
        {
            "name": "yolov8m-aug-100epochs-ships-vehicles_20250518",
            "path": "/kaggle/input/dpm3-models/models/yolov8m-aug-100epochs-ships-vehicles_20250518.pt",
            "type": "yolo",
            "use_for_eval": False,
        },
        {
            "name": "yolov8m-aug-update_20250603",
            "path": "/kaggle/input/dpm3-models/models/yolov8m-aug-update_20250603.pt",
            "type": "yolo",
            "use_for_eval": True,
        },
        {
            "name": "yolov8m-baseline-aug_20250518",
            "path": "/kaggle/input/dpm3-models/models/yolov8m-baseline-aug_20250518.pt",
            "type": "yolo",
            "use_for_eval": False,
        },
        {
            "name": "yolov8m-baseline_20250518",
            "path": "/kaggle/input/dpm3-models/models/yolov8m-baseline_20250518.pt",
            "type": "yolo",
            "use_for_eval": False,
        },
        {
            "name": "rf-detr",
            "path": "/kaggle/input/dpm3-models/models/rfdetr_best_total.pth",
            "type": "rfdetr",
            "use_for_eval": True,
        },
    ]
}

models_eval_config =  [model for model in models_config["models"] if model.get("use_for_eval", False)]
models_eval_config
```

```python _cell_guid="be5f7612-377c-4750-9af0-8eba7aa29a05" _uuid="8c62923c-596f-4f5c-bc4c-f7a623ed24b7" jupyter={"outputs_hidden": false} papermill={"duration": 0.077863, "end_time": "2025-07-26T17:25:50.992582", "exception": false, "start_time": "2025-07-26T17:25:50.914719", "status": "completed"}
from yaml import safe_load
from typing import Iterator, Any

models = models_config["models"]

def get_model_for_config(model: dict[str, Any], config: dict = None) -> Any:
    if not config: 
        config = dict()

    if model["type"] == "rtdetr":
        return UltralyticsModel(model["path"], config)
    elif model["type"] == "faster-rcnn":
        return FasterRCNNModel(model["path"], config)
    elif model["type"] == "yolo":
        return UltralyticsModel(model["path"], config)
    elif model["type"] == "rfdetr":
        return RFDETRModel(model["path"], config)


def all_model_loader(configs: list[dict[str, Any]], config = None) -> Iterator[tuple[str, Any]]:
    if not config: 
        config = dict()

    for model_info in configs:
        model_type = model_info["type"]
        name = model_info["name"]
        path = model_info["path"]

        if model_type == "rtdetr":
            yield name, UltralyticsModel(path, config)
        elif model_type == "faster-rcnn":
            yield name, FasterRCNNModel(path, config)
        elif model_type == "yolo":
            yield name, UltralyticsModel(path, config)
        elif model_type == "rfdetr":
            yield name, RFDETRModel(path, config)
        else:
            raise ValueError(f"Unknown model type: {model_type}")
```

```python _cell_guid="bddff5f7-83f0-46b1-956f-d582bf02a661" _uuid="2ba1ad13-f1f9-4ff6-93be-0d8eba769b20" jupyter={"outputs_hidden": false} papermill={"duration": 0.037294, "end_time": "2025-07-26T17:25:51.056156", "exception": false, "start_time": "2025-07-26T17:25:51.018862", "status": "completed"}
models
```

```python _cell_guid="11bfcef0-082d-4be9-9c00-aa32c91e6c2e" _uuid="ddf8ccf7-6043-4f3f-a479-10ddb5595fdb" jupyter={"outputs_hidden": false} papermill={"duration": 8.162264, "end_time": "2025-07-26T17:25:59.244492", "exception": false, "start_time": "2025-07-26T17:25:51.082228", "status": "completed"}
DATA_DIR = "/kaggle/input/skyfusion-yolo-v8/SkyFusion_yolo"
dataset = SkyFusionDataset(DATA_DIR, config=dict(), split="valid")
dataset
```

```python _cell_guid="e510a740-9343-4e5f-97fc-3802336814cb" _uuid="1e0ba1ed-0542-4ef6-964a-4a87f66200f4" jupyter={"outputs_hidden": false} papermill={"duration": 52.892559, "end_time": "2025-07-26T17:26:52.168001", "exception": false, "start_time": "2025-07-26T17:25:59.275442", "status": "completed"}
import cv2
import numpy as np
import matplotlib.pyplot as plt
from typing import List, Dict, Any


def draw_boxes(image_bgr: np.ndarray, boxes: List[object], color: tuple, show_confidence: bool = False) -> np.ndarray:
    """
    Draws bounding boxes on an image.

    Args:
        image_bgr (np.ndarray): Image in BGR format.
        boxes (List[object]): List of annotations or detections (must have bbox and class_name attributes).
        color (tuple): Color for the bounding boxes (B, G, R).
        show_confidence (bool): If True, includes confidence in the label.

    Returns:
        np.ndarray: Annotated image.
    """
    output_image = image_bgr.copy()

    for box in boxes:
        x1, y1, x2, y2 = map(int, box.bbox)
        label = box.class_name
        if show_confidence and hasattr(box, 'confidence'):
            label += f" {box.confidence:.2f}"

        cv2.rectangle(output_image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(output_image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

    return output_image


def compare_model_predictions(sample: Any, configs: list[dict[str, Any]]) -> None:
    image: np.ndarray = sample.image
    ground_truth_annotations = sample.annotations
    h, w, _ = image.shape

    for model_name, model in all_model_loader(models):
        predictions = model.predict(image)

        image_with_gt = draw_boxes(image, ground_truth_annotations, color=(255, 0, 0))
        image_with_preds = draw_boxes(image, predictions, color=(0, 255, 0), show_confidence=True)

        comparison_image = np.hstack((image_with_gt, image_with_preds))

        label_bar = np.zeros((50, w * 2, 3), dtype=np.uint8)
        cv2.putText(label_bar, "Ground Truth (Blue)", (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(label_bar, f"'{model_name}' Predictions (Green)", (w + 10, 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        final_image_bgr = np.vstack((label_bar, comparison_image))
        final_image_rgb = cv2.cvtColor(final_image_bgr, cv2.COLOR_BGR2RGB)

        plt.figure(figsize=(16, 10))
        plt.imshow(final_image_rgb)
        plt.axis('off')
        plt.title(f"Ground Truth vs. '{model_name}' Predictions", fontsize=16)
        plt.tight_layout()
        plt.show()


# # Assuming `dataset` and `models` are defined
sample = dataset[3]
compare_model_predictions(sample, models)
```

<!-- #region _cell_guid="c9e7c309-9bd0-4878-b4cc-52e7875cab8d" _uuid="43640fed-fad4-4bad-ab75-998e770af5d5" jupyter={"outputs_hidden": false} papermill={"duration": 0.294513, "end_time": "2025-07-26T17:26:52.776172", "exception": false, "start_time": "2025-07-26T17:26:52.481659", "status": "completed"} -->
 ## 2. Post-processing Sensitivity Study: NMS & Confidence Threshold Sweep
<!-- #endregion -->

```python _cell_guid="84c25262-0284-4832-b401-18e240448c4a" _uuid="a50317d7-dbdf-4751-b9a8-ecbffc5eedb0" jupyter={"outputs_hidden": false} papermill={"duration": 0.302999, "end_time": "2025-07-26T17:26:53.364763", "exception": false, "start_time": "2025-07-26T17:26:53.061764", "status": "completed"}
part1_eval, part2_eval = models_eval_config[:3], models_eval_config[3:]
part1_eval
```

```python papermill={"duration": 0.294228, "end_time": "2025-07-26T17:26:53.945237", "exception": false, "start_time": "2025-07-26T17:26:53.651009", "status": "completed"}
part2_eval
```

```python _cell_guid="77ac1679-78bd-4432-b4bc-da709c5692db" _uuid="f2cd9364-d5dd-4a6e-a84f-f8e7b82442bf" jupyter={"outputs_hidden": false} papermill={"duration": 24675.417621, "end_time": "2025-07-27T00:18:09.649856", "exception": false, "start_time": "2025-07-26T17:26:54.232235", "status": "completed"}
import gc
import optuna
import pandas as pd
from copy import deepcopy
from typing import List, Dict, Any
from src.odc.benchmark.metrics import DetectionMetrics

# -------------------- DEV FLAG --------------------
RUN_FAST_DEV: bool = False

# -------------------- Configurable Ranges --------------------
NMS_IOU_RANGE = (0.30, 0.80)
CONF_THRESH_RANGE = (0.05, 0.60)
LIMIT_IMGS = 2 if RUN_FAST_DEV else 400
PRUNING_INTERVAL = 5 if RUN_FAST_DEV else 100

N_TRIALS_WITH_NMS = 3 if RUN_FAST_DEV else 15
N_TRIALS_NO_NMS = 2 if RUN_FAST_DEV else 10

# -------------------- Dataset --------------------
inf_dataset = dataset[:LIMIT_IMGS]
class_names = dataset.class_names if hasattr(dataset, 'class_names') else dataset.get_class_names()


def instantiate_model_with_thresholds(model_info: Dict[str, Any], conf_thr: float, nms_thr: float):
    config = deepcopy(model_info.get("config", {}))
    config["conf_threshold"] = conf_thr
    config["iou_threshold"] = nms_thr

    model_type = model_info["type"]
    model_path = model_info["path"]

    if model_type in {"rtdetr", "yolo"}:
        return UltralyticsModel(model_path, config)
    elif model_type == "faster-rcnn":
        return FasterRCNNModel(model_path, config)
    elif model_type == "rfdetr":
        return RFDETRModel(model_path, config)
    else:
        raise ValueError(f"Unknown model type: {model_type}")


def _objective_impl(trial: optuna.Trial, model_info: Dict[str, Any], conf_thr: float, nms_thr: float) -> float:
    model = instantiate_model_with_thresholds(model_info, conf_thr, nms_thr)
    preds, gts = [], []
    metrics = DetectionMetrics(class_names)

    for i, sample in enumerate(inf_dataset):
        preds.append(model.predict(sample.image))
        gts.append(sample.annotations)

        if (i + 1) % PRUNING_INTERVAL == 0:
            metrics_out = metrics.calculate_comprehensive_metrics(preds, gts)
            map_50 = metrics_out.get("map_50", 0.0)
            trial.report(map_50, step=i + 1)
            if not RUN_FAST_DEV and trial.should_prune():
                raise optuna.TrialPruned()

    metrics_out = metrics.calculate_comprehensive_metrics(preds, gts)
    # store all metrics as user attributes for later retrieval
    for key, val in metrics_out.items():
        trial.set_user_attr(key, val)

    return metrics_out["map_50"] # ensure it is calculated


def _create_objective_with_nms(model_info: Dict[str, Any]):
    def objective(trial: optuna.Trial) -> float:
        conf_thr = trial.suggest_float("conf_thr", *CONF_THRESH_RANGE)
        nms_thr = trial.suggest_float("nms_iou", *NMS_IOU_RANGE)
        return _objective_impl(trial, model_info, conf_thr, nms_thr)
    return objective


def _create_objective_fixed_nms(model_info: Dict[str, Any]):
    fixed_nms = 0.0  # any constant, not used by RFDETR
    def objective(trial: optuna.Trial) -> float:
        conf_thr = trial.suggest_float("conf_thr", *CONF_THRESH_RANGE)
        nms_thr = fixed_nms
        return _objective_impl(trial, model_info, conf_thr, nms_thr)
    return objective


def create_objective(model_info: Dict[str, Any]):
    model_type = model_info["type"]
    if model_type in {"rfdetr", "rtdetr"}:
        return _create_objective_fixed_nms(model_info)
    else:
        return _create_objective_with_nms(model_info)


def run_optimization_for_model(model_info: Dict[str, Any], n_trials: int) -> pd.DataFrame:
    pruner = None if RUN_FAST_DEV else optuna.pruners.MedianPruner(n_warmup_steps=2)

    study = optuna.create_study(
        direction="maximize",
        pruner=pruner,
        storage="sqlite:///optuna_study.db",   # add this line for persistence
        study_name=model_info["name"],          # name study uniquely per model
        load_if_exists=True                      # load if study already exists
    )
    study.optimize(create_objective(model_info), n_trials=n_trials)

    trials_data = []
    for t in study.trials:
        data = {
            "model": model_info["name"],
            "conf_thr": t.params["conf_thr"],
            "nms_iou": t.params.get("nms_iou", None), # doesn't exist for DETR models
            "map_50": t.value,
            "state": str(t.state),
        }
        # merge user_attrs metrics
        data.update(t.user_attrs)
        trials_data.append(data)

    return pd.DataFrame(trials_data)


# -------------------- Run Optimization --------------------
all_results: List[pd.DataFrame] = []

for model_info in part1_eval:
    print(f"\nðŸš€ Starting optimization for: {model_info['name']}")
    model_type = model_info["type"]
    if model_type in {"rfdetr", "rtdetr"}:
        n_trials = N_TRIALS_NO_NMS
    else:
        n_trials = N_TRIALS_WITH_NMS
    
    df = run_optimization_for_model(model_info, n_trials=n_trials)
    all_results.append(df)
    gc.collect()


results_df = pd.concat(all_results)
results_df.to_csv("nms_conf_sweep_results.csv", index=False)
```

```python _cell_guid="b5d519ac-520b-4fff-a456-43121029ab1e" _uuid="945ced61-235f-4191-9fcb-003d3fd4f23f" jupyter={"outputs_hidden": false} papermill={"duration": 1.469482, "end_time": "2025-07-27T00:18:12.613520", "exception": false, "start_time": "2025-07-27T00:18:11.144038", "status": "completed"}
pd.read_csv("/kaggle/working/nms_conf_sweep_results.csv").head()
```

<!-- #region papermill={"duration": 1.37908, "end_time": "2025-07-27T00:18:15.514523", "exception": false, "start_time": "2025-07-27T00:18:14.135443", "status": "completed"} -->
#### Tuning is done on the valid set, so test set persists unseen and used only for final model testing the final model evaluation.
<!-- #endregion -->
