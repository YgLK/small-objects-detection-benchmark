---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.17.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

<!-- #region _cell_guid="5ebc3967-bac5-4b0a-990f-460f04d45e3d" _uuid="c51178f8-a3d8-4be7-acb4-fef99084de2e" jupyter={"outputs_hidden": false} papermill={"duration": 0.003029, "end_time": "2025-07-20T17:01:59.395024", "exception": false, "start_time": "2025-07-20T17:01:59.391995", "status": "completed"} -->
### Notebook with example of inference and evaluation:

https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-finetune-rf-detr-on-detection-dataset.ipynb
<!-- #endregion -->

```python _cell_guid="2d7e118a-ccdf-4eae-ac13-8ddfcc77c1ac" _uuid="46e582dd-74d2-4a64-8b1b-2dec95893dc0" jupyter={"outputs_hidden": false} papermill={"duration": 98.468299, "end_time": "2025-07-20T17:03:37.866051", "exception": false, "start_time": "2025-07-20T17:01:59.397752", "status": "completed"}
pip install "rfdetr[metrics]"
```

<!-- #region _cell_guid="64341089-d001-42fb-9233-88e76af9cccd" _uuid="39e52b36-1343-407c-a6c5-d951f6c4f8e3" jupyter={"outputs_hidden": false} papermill={"duration": 0.026231, "end_time": "2025-07-20T17:03:37.918064", "exception": false, "start_time": "2025-07-20T17:03:37.891833", "status": "completed"} -->
#### Dataset prep since RF-DETR require for some reason additional superclass field in annotations...
<!-- #endregion -->

```python _cell_guid="c16684b5-ac79-4ae9-abd4-aef8d29df117" _uuid="b6727681-0c08-4e54-bee0-1ac3a9258f81" jupyter={"outputs_hidden": false} papermill={"duration": 0.031115, "end_time": "2025-07-20T17:03:37.975054", "exception": false, "start_time": "2025-07-20T17:03:37.943939", "status": "completed"}
# !cp -r /kaggle/input/skyfusion-coco-augmented ./
```

```python _cell_guid="bab789fb-6873-410e-ab06-1f7c7923bb7f" _uuid="871a4aac-dcfe-4916-9a4b-886c8318ca1b" jupyter={"outputs_hidden": false} papermill={"duration": 0.031283, "end_time": "2025-07-20T17:03:38.031649", "exception": false, "start_time": "2025-07-20T17:03:38.000366", "status": "completed"}
# import json
# from pathlib import Path
# from typing import List


# def sync_supercategory_with_name(file_paths: List[Path]) -> None:
#     """
#     Sets 'supercategory' equal to 'name' for each category in multiple annotation files.

#     Args:
#         file_paths (List[Path]): List of annotation file paths.
#     """
#     for file_path in file_paths:
#         if not file_path.exists():
#             print(f"File not found: {file_path}")
#             continue

#         with open(file_path, "r") as f:
#             anns = json.load(f)

#         for category in anns.get("categories", []):
#             category["supercategory"] = category["name"]

#         with open(file_path, "w") as f:
#             json.dump(anns, f, indent=4)

#         print(f"Updated supercategory in {file_path}")


# # dataset directory path
# DATASET_DIR = Path("/kaggle/working/skyfusion-coco-augmented/SkyFusion_augmented")

# # list of annotation files for all splits
# file_paths_to_update = [
#     DATASET_DIR / "train" / "_annotations.coco.json",
#     DATASET_DIR / "valid" / "_annotations.coco.json",
#     DATASET_DIR / "test" / "_annotations.coco.json",
# ]

# # update all sets
# sync_supercategory_with_name(file_paths_to_update)
```

```python _cell_guid="588a92ac-2f35-461b-85dd-62fdd208f2a8" _uuid="ec10bdb4-73a1-42d1-a7d0-f19ced0a970f" jupyter={"outputs_hidden": false} papermill={"duration": 2.553061, "end_time": "2025-07-20T17:03:40.610055", "exception": false, "start_time": "2025-07-20T17:03:38.056994", "status": "completed"}
import wandb
# Initialize wandb - make sure to set WANDB_API_KEY environment variable
from kaggle_secrets import UserSecretsClient
secret_label = "WANDB_API_KEY"
wb_api_key = UserSecretsClient().get_secret(secret_label)
wandb.login(key=wb_api_key)

```

```python papermill={"duration": 2.146919, "end_time": "2025-07-20T17:03:42.854325", "exception": false, "start_time": "2025-07-20T17:03:40.707406", "status": "completed"}
import wandb

WANDB_PROJECT_NAME = "RF-DETR_skyfusion"

wandb.init(
    project=WANDB_PROJECT_NAME,
    id="o59ofbts",
    resume="allow"
)
```

```python papermill={"duration": 0.032983, "end_time": "2025-07-20T17:03:42.915966", "exception": false, "start_time": "2025-07-20T17:03:42.882983", "status": "completed"}
DATASET_DIR = "/kaggle/input/rf-detr-oom-error/skyfusion-coco-augmented/SkyFusion_augmented"
```

```python _cell_guid="c36cb572-9bd6-420a-b8a5-3e231e6d75c6" _uuid="90e9fefd-9989-41c2-8348-0b5e57daaee0" jupyter={"outputs_hidden": false} papermill={"duration": 17127.443951, "end_time": "2025-07-20T21:49:10.387357", "exception": false, "start_time": "2025-07-20T17:03:42.943406", "status": "completed"}
from rfdetr import RFDETRBase

# Use class_map to map from dataset IDs (1,2,3) to model IDs (0,1,2)
model = RFDETRBase(
    device="cuda", 
    num_classes=3,
    class_map={1: 0, 2: 1, 3: 2},  # Map from dataset class ID to model class ID
)

model.train(
    dataset_dir=DATASET_DIR,
    epochs=15,
    batch_size=1,
    grad_accum_steps=8,
    lr=5e-5,  # Reduced from 1e-4 to match the effective batch size ratio in the tutorial
    early_stopping=True,
    early_stopping_patience=3,
    wandb=True,
    project=WANDB_PROJECT_NAME,
    resume="/kaggle/input/rf-detr-oom-error/output/checkpoint.pth" # continue from 5th epoch
)
```

```python papermill={"duration": 0.105194, "end_time": "2025-07-20T21:49:10.592069", "exception": false, "start_time": "2025-07-20T21:49:10.486875", "status": "completed"}
# import torch

# checkpoint = torch.load("/kaggle/input/rf-detr-oom-error/output/checkpoint_best_ema.pth", weights_only=False)

# # see what keys exist
# print(checkpoint.keys())
# print(checkpoint["epoch"])
```

<!-- #region papermill={"duration": 0.095671, "end_time": "2025-07-20T21:49:10.811017", "exception": false, "start_time": "2025-07-20T21:49:10.715346", "status": "completed"} -->
The mapping remains available during evaluation. When model.evaluate() is called on a model instance initialized with class_map={1: 0, 2: 1, 3: 2}, that mapping is used for the evaluation process.
<!-- #endregion -->

```python papermill={"duration": 0.102779, "end_time": "2025-07-20T21:49:11.009643", "exception": false, "start_time": "2025-07-20T21:49:10.906864", "status": "completed"}
# from rfdetr import RFDETRBase

# model = RFDETRBase(
#     device="cuda", 
#     num_classes=3,
#     class_map={1: 0, 2: 1, 3: 2},  # Map from dataset class ID to model class ID
#     pretrain_weights="/kaggle/input/rf-detr-oom-error/output/checkpoint.pth"
# )
# model
```

```python papermill={"duration": 6.898902, "end_time": "2025-07-20T21:49:18.006170", "exception": false, "start_time": "2025-07-20T21:49:11.107268", "status": "completed"}
from pycocotools.coco import COCO
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import numpy as np
import os

# Load the COCO dataset
coco = COCO(f"{DATASET_DIR}/test/_annotations.coco.json")

# Get class names
categories = coco.loadCats(coco.getCatIds())
class_names = {cat['id']: cat['name'] for cat in categories}

# Choose an image
img_ids = list(coco.imgs.keys())

for idx in range(10):
    img_id = img_ids[idx]  # Choose any index
    img_info = coco.loadImgs(img_id)[0]
    img_path = os.path.join(f"{DATASET_DIR}/test", img_info['file_name'])
    
    # Load image
    image = Image.open(img_path).convert("RGB")
    image_array = np.array(image)
    
    # Make prediction with your model
    detections = model.predict(img_path, threshold=0.5)
    
    # Set up plot
    fig, ax = plt.subplots(1, 2, figsize=(14, 7))
    
    # Plot original image
    ax[0].imshow(image)
    ax[0].set_title("Original Image")
    ax[0].axis('off')
    
    # Get ground truth annotations for this image
    ann_ids = coco.getAnnIds(imgIds=img_id)
    annotations = coco.loadAnns(ann_ids)
    
    # Draw ground truth boxes
    for ann in annotations:
        bbox = ann['bbox']  # [x, y, width, height]
        x, y, w, h = bbox
        category_id = ann['category_id']
        class_name = class_names[category_id]
        
        # Draw rectangle (convert COCO format [x,y,w,h] to [x1,y1,x2,y2])
        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='green', facecolor='none')
        ax[0].add_patch(rect)
        # Add label
        ax[0].text(x, y-5, class_name, color='green', fontsize=10, 
                   bbox=dict(facecolor='white', alpha=0.7))
    
    # Plot image with detections
    ax[1].imshow(image)
    ax[1].set_title("Detections")
    ax[1].axis('off')
    
    # Draw detection boxes
    for i, box in enumerate(detections.xyxy):
        x1, y1, x2, y2 = box
        class_id = detections.class_id[i]
        confidence = detections.confidence[i]
        
        # Convert from model class ID back to dataset class ID using inverse mapping
        inverse_class_map = {v: k for k, v in model.class_map.items()} if hasattr(model, 'class_map') else {}
        dataset_class_id = inverse_class_map.get(class_id, class_id)
        
        # Get class name
        class_name = class_names.get(dataset_class_id, f"Class {dataset_class_id}")
        
        # Draw rectangle
        rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='red', facecolor='none')
        ax[1].add_patch(rect)
        # Add label
        ax[1].text(x1, y1-5, f"{class_name}: {confidence:.2f}", 
                  color='red', fontsize=10, bbox=dict(facecolor='white', alpha=0.7))
    
    plt.tight_layout()
    plt.show()
    
    # Print detection details
    print(f"Found {len(detections.xyxy)} objects:")
    for i, box in enumerate(detections.xyxy):
        class_id = detections.class_id[i]
        inverse_class_map = {v: k for k, v in model.class_map.items()} if hasattr(model, 'class_map') else {}
        dataset_class_id = inverse_class_map.get(class_id, class_id)
        class_name = class_names.get(dataset_class_id, f"Class {dataset_class_id}")
        confidence = detections.confidence[i]
        print(f"  {i+1}. {class_name} (ID: {dataset_class_id}): {confidence:.2f}, bbox: {detections.xyxy[i]}")
```

```python papermill={"duration": 0.24218, "end_time": "2025-07-20T21:49:18.487346", "exception": false, "start_time": "2025-07-20T21:49:18.245166", "status": "completed"}
# from rfdetr import RFDETRBase

# # Path to your saved best model
# model_path = "outputs/YOUR_TIMESTAMP/best.pt"

# # Load the model
# model = RFDETRBase(
#     device="cuda",
#     num_classes=3,
#     class_map={1: 0, 2: 1, 3: 2}
# )
# model.load(model_path)

# # Run inference on a single image
# result = model.predict("path/to/image.jpg")

# # Or evaluate on test set
# metrics = model.evaluate(
#     dataset_dir=DATASET_DIR.as_posix(),
#     split="test"
# )
```
