---
jupyter:
  jupytext:
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.17.3
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

<!-- #region _cell_guid="a9ae86b0-b05f-4daf-9474-6035c460dbde" _uuid="8fed7d05-00a3-496d-ab6d-97768c50c1df" jupyter={"outputs_hidden": false} papermill={"duration": 0.004292, "end_time": "2025-07-12T17:41:06.238233", "exception": false, "start_time": "2025-07-12T17:41:06.233941", "status": "completed"} -->
# PyTorch Lightning Faster R-CNN Finetuning LB=0.358


Finetune TorchVision's [Faster R-CNN](https://pytorch.org/vision/stable/models.html#id57) with [PyTorch Lightninng](https://www.pytorchlightning.ai/).

Tracks the training with [Weights & Biases](https://wandb.ai/site).

Corresponding Inference kernel: [Starter PyTorch Lightning Faster R-CNN Inference](https://www.kaggle.com/clemchris/starter-pytorch-lightning-faster-r-cnn-inference)

## Lightninng Features Used in this Kernel:
- Easily switch between CPU and GPU training (`gpus=[0/1]` Trainer flag)
- Quickly check if complete training is running without errors with `fast_dev_run=True` Trainer flag
- Use half precision training on GPU with `precision=16` Trainer flag
- Log learning rate with `LearningRateMonitor` callback
- Log losses and metrics to Weights & Biases with `WandbLogger`

## Ideas for next steps:
- Add data augmentation
- Use also those image without annotations for training
- Try other TorchVision models
- Try TPU training (made easy with PyTorch Lightning's [TPU Support](https://pytorch-lightning.readthedocs.io/en/latest/advanced/tpu.html))
- Tune hyperparameters of model
- Visualize inputs and predictions with Weights & Biases

## Sources and Inspirations:
- [TorchVision Object Detection Finetuning Tutorial](https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html)
- [Reef- Starter Torch FasterRCNN Train [LB=0.416]](https://www.kaggle.com/julian3833/reef-starter-torch-fasterrcnn-train-lb-0-416)
<!-- #endregion -->

<!-- #region _cell_guid="589c653d-48df-4b16-bbf0-50a22489e4c7" _uuid="ef9b3277-2472-4fc7-b8bc-1841e223fb7c" jupyter={"outputs_hidden": false} papermill={"duration": 0.003353, "end_time": "2025-07-12T17:41:06.245257", "exception": false, "start_time": "2025-07-12T17:41:06.241904", "status": "completed"} -->
## Installs

Let's use the latest versions of PyTorch Lightning and [TorchMetrics](https://torchmetrics.readthedocs.io/en/latest/) to be able to use TorchMetric's [MAP](https://torchmetrics.readthedocs.io/en/latest/references/modules.html#map) metric, which needs [pycocotools](https://github.com/cocodataset/cocoapi/tree/master/PythonAPI/pycocotools).
<!-- #endregion -->

```python _cell_guid="0e2df8f0-f92d-48a4-abf8-f7aaaf04bd6e" _uuid="c10ed2cf-3aca-459f-804c-92709ea7b2ba" jupyter={"outputs_hidden": false} papermill={"duration": 0.009451, "end_time": "2025-07-12T17:41:06.258046", "exception": false, "start_time": "2025-07-12T17:41:06.248595", "status": "completed"}
# pip install pytorch-lightning==1.5.3 torchmetrics==0.6.0 pycocotools
```

<!-- #region _cell_guid="572c9537-1053-437e-9920-e211df250543" _uuid="1c7b6137-2764-48c1-9df5-cccd850bb1d2" jupyter={"outputs_hidden": false} papermill={"duration": 0.003126, "end_time": "2025-07-12T17:41:06.264616", "exception": false, "start_time": "2025-07-12T17:41:06.261490", "status": "completed"} -->
## Imports
<!-- #endregion -->

```python _cell_guid="08eef860-ae1f-4e51-a26e-92a36750f9c2" _uuid="7e0f3744-a420-49ea-bca9-a15df97752b3" jupyter={"outputs_hidden": false} papermill={"duration": 19.33461, "end_time": "2025-07-12T17:41:25.602577", "exception": false, "start_time": "2025-07-12T17:41:06.267967", "status": "completed"}
import ast
import math
import multiprocessing as mp
import os
import json
from pathlib import Path

import numpy as np
import pandas as pd
import pytorch_lightning as pl
import torch
import torchmetrics
import torchvision
import wandb
from PIL import Image

from pytorch_lightning.callbacks import LearningRateMonitor
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.loggers import WandbLogger

from torchmetrics.metric import Metric
from torchvision.datasets import VisionDataset
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torch.utils.data.dataloader import DataLoader
from pycocotools.coco import COCO
```

<!-- #region _cell_guid="54bdbc87-e340-4a7c-8a76-0d7c085d85e6" _uuid="ea5606f0-314f-4b92-a4ca-7b772e57f9a2" jupyter={"outputs_hidden": false} papermill={"duration": 0.003394, "end_time": "2025-07-12T17:41:25.609761", "exception": false, "start_time": "2025-07-12T17:41:25.606367", "status": "completed"} -->
## Load Weights & Biases API Key from secrets
- Copy key from [W&B settings page](https://wandb.ai/settings)
- Add key to Kaggle through [Add-ons](https://www.kaggle.com/product-feedback/114053)
<!-- #endregion -->

```python _cell_guid="409d167a-bef5-4fa0-b73c-e8e4b330cd30" _uuid="f3b3cb39-fd94-4427-92df-4928ef19c490" jupyter={"outputs_hidden": false} papermill={"duration": 0.32027, "end_time": "2025-07-12T17:41:25.933350", "exception": false, "start_time": "2025-07-12T17:41:25.613080", "status": "completed"}
# Initialize wandb - make sure to set WANDB_API_KEY environment variable
from kaggle_secrets import UserSecretsClient
secret_label = "WANDB_API_KEY"
wb_api_key = UserSecretsClient().get_secret(secret_label)
wandb.login(key=wb_api_key)
```

<!-- #region _cell_guid="70a353b5-d7c4-4fc3-81b0-8814d46f4c31" _uuid="239a944e-74b9-44a5-a045-1a19f03d4d73" jupyter={"outputs_hidden": false} papermill={"duration": 0.003441, "end_time": "2025-07-12T17:41:25.941582", "exception": false, "start_time": "2025-07-12T17:41:25.938141", "status": "completed"} -->
## Paths
<!-- #endregion -->

```python _cell_guid="2d3d2478-62e6-413e-b36e-9b73941f2f32" _uuid="5db1bc41-d1d6-4f52-b88c-05a7c22c579c" jupyter={"outputs_hidden": false} papermill={"duration": 0.008895, "end_time": "2025-07-12T17:41:25.954081", "exception": false, "start_time": "2025-07-12T17:41:25.945186", "status": "completed"}
# Updated paths for SkyFusion dataset
DATA_DIR = Path("/kaggle/input/skyfusion-coco-augmented/SkyFusion_augmented")
TRAIN_DIR = DATA_DIR / "train"
VAL_DIR = DATA_DIR / "valid"
TRAIN_ANNOTATIONS = TRAIN_DIR / "_annotations.coco.json"
VAL_ANNOTATIONS = VAL_DIR / "_annotations.coco.json"
```

<!-- #region _cell_guid="52ffc58e-6c06-4a5b-9a10-f6569bc92efd" _uuid="529027d0-0bc7-41d0-adbb-dff55589779e" jupyter={"outputs_hidden": false} papermill={"duration": 0.003312, "end_time": "2025-07-12T17:41:25.961306", "exception": false, "start_time": "2025-07-12T17:41:25.957994", "status": "completed"} -->
## Settings
<!-- #endregion -->

```python _cell_guid="47d96435-c3ff-429f-8d06-0483197bdb0c" _uuid="7c2615dd-1358-46ee-bc42-c962c1d7f2b9" jupyter={"outputs_hidden": false} papermill={"duration": 1.944108, "end_time": "2025-07-12T17:41:27.908920", "exception": false, "start_time": "2025-07-12T17:41:25.964812", "status": "completed"}
# Data Module Args
NUM_WORKERS = mp.cpu_count()
BATCH_SIZE = 2

WANDB_PROJECT = "skyfusion-object-detection_TEST"
wandb.init(project=WANDB_PROJECT)

# Trainer Args
GPUS = 1             # Set to 1 if GPU is enabled for notebook
MAX_EPOCHS = 50
```

<!-- #region _cell_guid="3afbeb59-9910-41cb-b1c1-25cbeb33aa6b" _uuid="2d987848-6ed4-49ab-abdf-3808e7821de9" jupyter={"outputs_hidden": false} papermill={"duration": 0.003743, "end_time": "2025-07-12T17:41:27.916913", "exception": false, "start_time": "2025-07-12T17:41:27.913170", "status": "completed"} -->
## PyTorch Dataset Class
<!-- #endregion -->

```python _cell_guid="cda8a5b5-bcc2-45c1-9fc7-8a6f5e486a68" _uuid="a26e2146-8f57-4bed-a628-dd2359576703" jupyter={"outputs_hidden": false} papermill={"duration": 0.012885, "end_time": "2025-07-12T17:41:27.933596", "exception": false, "start_time": "2025-07-12T17:41:27.920711", "status": "completed"}
class SkyFusionDataset(VisionDataset):
    """Custom VisionDataset class that creates a dataset from COCO annotations.
       
       Works with SkyFusion dataset in COCO format.
       Classes: aircraft (1), ship (2), vehicle (3)
    """
    
    def __init__(self, annotation_file, image_dir):
        super().__init__(image_dir)
        
        self.annotation_file = annotation_file
        self.image_dir = Path(image_dir)
        
        # Load COCO annotations
        self.coco = COCO(annotation_file)
        
        # Get all image IDs that have annotations
        self.image_ids = list(self.coco.imgs.keys())
        
        # Filter to only images with annotations
        self.image_ids = [img_id for img_id in self.image_ids 
                         if len(self.coco.getAnnIds(imgIds=img_id)) > 0]

    def __getitem__(self, index):
        image_id = self.image_ids[index]
        
        # Get image info
        img_info = self.coco.loadImgs(image_id)[0]
        image_path = self.image_dir / img_info['file_name']
        
        # Load image
        image = Image.open(image_path).convert("RGB")
        image = np.array(image, dtype=np.float32) / 255.0
        
        # Get annotations
        ann_ids = self.coco.getAnnIds(imgIds=image_id)
        annotations = self.coco.loadAnns(ann_ids)
        
        # Convert annotations to required format
        boxes = []
        labels = []
        
        for ann in annotations:
            # COCO format: [x, y, width, height] -> [x_min, y_min, x_max, y_max]
            x, y, w, h = ann['bbox']
            boxes.append([x, y, x + w, y + h])
            labels.append(ann['category_id'])
        
        # Convert to tensors
        image = torch.from_numpy(image.transpose(2, 0, 1))
        
        target = {}
        target["boxes"] = torch.as_tensor(boxes, dtype=torch.float32)
        target["labels"] = torch.as_tensor(labels, dtype=torch.int64)
        target["image_id"] = torch.tensor([image_id])
        
        return image, target

    def __len__(self) -> int:
        return len(self.image_ids)
```

<!-- #region _cell_guid="726d6e62-c88e-4ab0-9b1c-402db7bd19a8" _uuid="a075b300-9b37-457a-9563-f13d184e3427" jupyter={"outputs_hidden": false} papermill={"duration": 0.003616, "end_time": "2025-07-12T17:41:27.941505", "exception": false, "start_time": "2025-07-12T17:41:27.937889", "status": "completed"} -->
## Lightning Module Class
<!-- #endregion -->

```python papermill={"duration": 0.172666, "end_time": "2025-07-12T17:41:28.118003", "exception": false, "start_time": "2025-07-12T17:41:27.945337", "status": "completed"}
import numpy as np  # make sure to import numpy
import torch
from PIL import Image, ImageDraw
import torchvision.transforms.functional as F
import wandb
from typing import Optional, List, Any, Dict
import cv2

CLASS_NAMES = {
    1: "aircraft",
    2: "ship",
    3: "vehicle",
}

def draw_and_log_images(
    images: torch.Tensor,
    targets: List[Dict[str, Any]],
    outputs: List[Dict[str, Any]],
    max_batches: int = 3,
    batch_idx: int = 0,
) -> None:
    """draw bounding boxes for ground truth and predictions on images and log to wandb.

    Args:
        images: batch of images, shape (B, C, H, W), tensor
        targets: list of dicts with ground truth boxes and labels
        outputs: list of dicts with predicted boxes, labels, and scores
        max_batches: maximum number of batches to log images from
        batch_idx: current batch index in validation loop
    """
    if batch_idx >= max_batches:
        return

    for img_tensor, target, output in zip(images, targets, outputs):
        # convert tensor to numpy image (H, W, C) and uint8
        img_np = img_tensor.permute(1, 2, 0).cpu().numpy()
        img_np = (img_np * 255).astype(np.uint8).copy()

        # convert RGB to BGR for OpenCV
        img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

        # draw ground truth boxes in green
        for box, label in zip(target["boxes"], target["labels"]):
            x1, y1, x2, y2 = map(int, box.tolist())
            class_name = CLASS_NAMES.get(int(label), str(int(label)))
            cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(img_cv, f"GT: {class_name}", (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

        # draw predicted boxes in red
        for box, label, score in zip(output["boxes"], output["labels"], output["scores"]):
            x1, y1, x2, y2 = map(int, box.tolist())
            class_name = CLASS_NAMES.get(int(label), str(int(label)))
            cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 0, 255), 2)
            cv2.putText(img_cv, f"Pred: {class_name} {score:.2f}", (x1, y2 + 15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        # convert back to RGB for wandb.Image
        img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)

        # log the image
        wandb.log({"val_image": wandb.Image(img_rgb)})

```

```python _cell_guid="d87a263e-1cc2-4ef9-a8b4-ec1916340212" _uuid="c244c593-d005-44c0-abd5-c82d03f69bb8" jupyter={"outputs_hidden": false} papermill={"duration": 0.020761, "end_time": "2025-07-12T17:41:28.143145", "exception": false, "start_time": "2025-07-12T17:41:28.122384", "status": "completed"}
from torchmetrics.detection.mean_ap import MeanAveragePrecision as MAP
from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights

class SkyFusionModule(pl.LightningModule):
    """LightningModule class to finetune torchvision's Faster R-CNN model."""
    
    def __init__(self, pretrained_weights_path=None):
        super().__init__()

        self.model = self._create_model(pretrained_weights_path)

        self.val_map = MAP()

    def _create_model(self, pretrained_weights_path):
        """Creates finetunable Faster R-CNN model.
        
        In the finetuning notebook, the internet can be used and the weights are downloaded.
        In the inference notebook, there is no internet access and the weights are provided
        with the pretrained_weights_path arg.
        """
        if pretrained_weights_path is None:
            model = fasterrcnn_resnet50_fpn(pretrained=True)
        else:
            # model = fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)
            # model.load_state_dict(torch.load(pretrained_weights_path))
            weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT
            model = fasterrcnn_resnet50_fpn(weights=weights)
        
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        # SkyFusion has 3 classes: aircraft, ship, vehicle + background = 4 classes
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=4)

        return model

    def forward(self, image):
        """Runs inference."""
        output = self.model(image)
        return output

    def training_step(self, batch, batch_idx):
        image, target = batch
        loss_dict = self.model(image, target)
        losses = sum(loss for loss in loss_dict.values())

        batch_size = len(batch[0])
        self.log_dict(loss_dict, batch_size=batch_size)
        self.log("train_loss", losses, batch_size=batch_size)

        return losses

    def validation_step(self, batch, batch_idx):
        image, target = batch
        output = self.model(image)

        batch_size = len(batch[0])
        val_map = self.val_map(output, target)
        self.log("val_map", val_map["map"], batch_size=batch_size)
        
        # log images with bounding boxes for first 3 batches only
        draw_and_log_images(image, target, output, max_batches=3, batch_idx=batch_idx)

    def configure_optimizers(self):
        params = [p for p in self.model.parameters() if p.requires_grad]
        optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)

        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

        return [optimizer], [lr_scheduler]
```

<!-- #region _cell_guid="f4e90c00-9ad9-435c-8523-c4dc5bc38a3f" _uuid="172886b9-4595-41fd-8316-faca00b61a3e" jupyter={"outputs_hidden": false} papermill={"duration": 0.008785, "end_time": "2025-07-12T17:41:28.158540", "exception": false, "start_time": "2025-07-12T17:41:28.149755", "status": "completed"} -->
## Lightning DataModule Class
<!-- #endregion -->

```python _cell_guid="a698417c-2f17-48db-ba71-b4a76a2b488c" _uuid="8afe8e25-bdb6-4270-9afb-6f8c18a077d9" jupyter={"outputs_hidden": false} papermill={"duration": 0.018921, "end_time": "2025-07-12T17:41:28.185559", "exception": false, "start_time": "2025-07-12T17:41:28.166638", "status": "completed"}
class SkyFusionDataModule(pl.LightningDataModule):
    """LightningDataModule class to handle SkyFusion dataset and create dataloaders."""
    def __init__(self, train_ann_file, train_img_dir, val_ann_file, val_img_dir, batch_size, num_workers):
        super().__init__()

        self.save_hyperparameters()

        self.train_ann_file = train_ann_file
        self.train_img_dir = train_img_dir
        self.val_ann_file = val_ann_file
        self.val_img_dir = val_img_dir
        self.batch_size = batch_size
        self.num_workers = num_workers

    def setup(self, stage=None):
        self.train_dataset = SkyFusionDataset(self.train_ann_file, self.train_img_dir)
        self.val_dataset = SkyFusionDataset(self.val_ann_file, self.val_img_dir)

    def train_dataloader(self):
        return self._dataloader(self.train_dataset, shuffle=True)

    def val_dataloader(self):
        return self._dataloader(self.val_dataset)

    def _dataloader(self, dataset, shuffle=False):
        return DataLoader(
            dataset,
            batch_size=self.batch_size,
            shuffle=shuffle,
            num_workers=self.num_workers,
            collate_fn=collate_fn,
            pin_memory=True,
            drop_last=True,
        )


def collate_fn(batch):
    return tuple(zip(*batch))
```

<!-- #region _cell_guid="ae0c7b30-1324-41c5-bd5a-42012651c046" _uuid="1fd8e7d1-d315-4ea2-aaaf-fc73e86fc2e8" jupyter={"outputs_hidden": false} papermill={"duration": 0.005321, "end_time": "2025-07-12T17:41:28.195265", "exception": false, "start_time": "2025-07-12T17:41:28.189944", "status": "completed"} -->
## Train Function
<!-- #endregion -->

```python _cell_guid="895fcf10-b28b-46d6-891d-f0d8c0508ce2" _uuid="5a922e38-8c7b-4da4-9975-bda4a0c5b83d" jupyter={"outputs_hidden": false} papermill={"duration": 0.012174, "end_time": "2025-07-12T17:41:28.213722", "exception": false, "start_time": "2025-07-12T17:41:28.201548", "status": "completed"}
def train():
    pl.seed_everything(42, workers=True)

    skyfusion_module = SkyFusionModule()

    skyfusion_data_module = SkyFusionDataModule(
        train_ann_file=TRAIN_ANNOTATIONS,
        train_img_dir=TRAIN_DIR,
        val_ann_file=VAL_ANNOTATIONS,
        val_img_dir=VAL_DIR,
        batch_size=BATCH_SIZE,
        num_workers=NUM_WORKERS
    )

    checkpoint_callback = ModelCheckpoint(
        monitor="val_map",
        mode="max",
        save_top_k=1,
        filename="best-checkpoint-{epoch:02d}-{val_map:.2f}",
        save_last=True,
        dirpath="checkpoints/"
    )

    early_stopping = EarlyStopping(
        monitor="val_map",
        mode="max",               # because higher val_map is better
        patience=5,
        verbose=True
    )

    trainer = pl.Trainer(
        fast_dev_run=False,
        max_epochs=MAX_EPOCHS,
        accelerator="gpu" if GPUS else "cpu",
        devices=GPUS if GPUS else 1,  # GPUS should be int or list of GPU ids
        callbacks=[early_stopping, checkpoint_callback],
        logger=WandbLogger(project=WANDB_PROJECT, log_model=True),
        gradient_clip_val=0.5,
        precision="16-mixed" if GPUS else 32,  # updated for PyTorch Lightning 2.0+
    )

    trainer.fit(skyfusion_module, skyfusion_data_module)
```

<!-- #region _cell_guid="f6cb2dcd-8dc1-4c72-980f-343ad19a6858" _uuid="b3f20a5f-9e57-4ce1-b81f-00970d10a04d" jupyter={"outputs_hidden": false} papermill={"duration": 0.003636, "end_time": "2025-07-12T17:41:28.221330", "exception": false, "start_time": "2025-07-12T17:41:28.217694", "status": "completed"} -->
## Run the Training
<!-- #endregion -->

```python _cell_guid="66cad61d-506f-42df-beb0-c29e7b3ec29b" _uuid="ae018cb4-a2f9-4465-bfab-430668ebd26e" jupyter={"outputs_hidden": false} papermill={"duration": 27456.818282, "end_time": "2025-07-13T01:19:05.043415", "exception": false, "start_time": "2025-07-12T17:41:28.225133", "status": "completed"}
train()
```
